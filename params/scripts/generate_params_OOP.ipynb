{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyDOE import *\n",
    "import xarray as xr\n",
    "import copy\n",
    "import netCDF4\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download latest version of params file from google drive\n",
    "* requires 'publishing' the google drive spreadsheet\n",
    "* file > publish to web\n",
    "* then it can be set up to continuously publish the spreadsheet to a stable url (with some latency, maybe 1-2 minutes)\n",
    "* note that the first tab must be the sheet where the relevant information is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQs413GtLXtHVDCqEPgAwn4BbDjoWmV7uFqOAWH4mgpxXoVfN6ijnJdhyRgLkV-n2eU-sSQush4CzYU/pub?output=csv'\n",
    "#cmd = 'curl '+data_url+' > params.csv'\n",
    "cmd = 'curl -L '+data_url+' > params.csv' # need to add -L option to force redirects\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a class for organizing parameter information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamInfo(object):\n",
    "    \"\"\"\n",
    "    Stores parameter information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, loc, minval=None, maxval=None, defval=None):\n",
    "        self._name = name # parameter name\n",
    "        self._min = minval # minimum value\n",
    "        self._max = maxval # maximum value\n",
    "        self._default = defval # default value\n",
    "        self._value = None # actual value to be used in a given ensemble member\n",
    "        self._location = loc # location of parameter (params file or namelist)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def min(self):\n",
    "        return self._min\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return self._max\n",
    "    \n",
    "    @property\n",
    "    def default(self):\n",
    "        return self._default\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "    \n",
    "    @property\n",
    "    def location(self):\n",
    "        return self._location\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, new_name):\n",
    "        self._name = new_name\n",
    "   \n",
    "    @min.setter\n",
    "    def min(self, new_min):\n",
    "        self._min = new_min\n",
    "        \n",
    "    @max.setter\n",
    "    def max(self, new_max):\n",
    "        self._max = new_max\n",
    "        \n",
    "    @default.setter\n",
    "    def default(self, new_def):\n",
    "        self._default = new_def\n",
    "        \n",
    "    @value.setter\n",
    "    def value(self, new_val):\n",
    "        self._value = new_val\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"%s:\\n\\tloc = %s\\n\\tdefault = %s\\n\\tmin = %s\\n\\tmax = %s\\n\\tvalue = %s\" % (self.name, self.location, self.default, self.min, self.max, self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add these or other unit tests to ParamInfo class itself\n",
    "# Check every time the code updates, or adding new functionality\n",
    "\n",
    "# testing out the class/dictionary functionality\n",
    "test_dict = {\"P1\": ParamInfo(\"P1\", minval=0.0, maxval=1.0, defval=2.0, loc='N'),\n",
    "             \"P2\": ParamInfo(\"P2\", minval=[0,0,0,0,0], maxval=[100,100,100,100,100], defval=[0,1,2,3,4], loc='P'),\n",
    "             \"P3\": ParamInfo(\"P3\", minval=\"min\", maxval=\"max\", defval=\"value\", loc='N'),\n",
    "             \"P4\": ParamInfo(\"P4\", loc='P')\n",
    "            }\n",
    "\n",
    "# example of adding a new parameter\n",
    "test_dict[\"new_param\"] = ParamInfo(\"new_param\", 'N')\n",
    "\n",
    "# example of setting the max value\n",
    "test_dict[\"P4\"].max = 200\n",
    "\n",
    "# example of setting the value for a given ensemble member\n",
    "test_dict[\"new_param\"].value = 100\n",
    "\n",
    "# look at the test dictionary\n",
    "for key in test_dict:\n",
    "    print(test_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a class for organizing ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Member(object):\n",
    "    \"\"\"\n",
    "    Stores and works with a bunch of ParamInfos.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, paraminfo):\n",
    "        self._name = name\n",
    "        self._paraminfo = paraminfo\n",
    "        \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def paraminfo(self):\n",
    "        return self._paraminfo\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, new_name):\n",
    "        self._name = new_name\n",
    "    \n",
    "    def get_names(self):\n",
    "        \"\"\"\n",
    "        Returns a list of parameter names.\n",
    "        \"\"\"\n",
    "        \n",
    "        names = []\n",
    "        for param in self._paraminfo:\n",
    "            names.append(self._paraminfo[param].name)\n",
    "        return names\n",
    "                 \n",
    "    def write(self, sampling_protocol):\n",
    "        \"\"\"\n",
    "        Writes files to disk for each member: param netcdf, namelist mods txt.\n",
    "        \"\"\"\n",
    "        \n",
    "        # generate file names based on member name\n",
    "        i = int(self._name)\n",
    "        self._pftfile = \"../paramfiles/\"+sampling_protocol+str(i+1).zfill(4)+\".nc\"\n",
    "        self._nlfile = \"../namelist_mods/\"+sampling_protocol+str(i+1).zfill(4)+\".txt\" \n",
    "        \n",
    "        # assign the basepftfile (this also happens in Ensemble class)\n",
    "        #self._basepftfile = \"../basecase/clm5_params.c200717.nc\"\n",
    "        #self._basepftfile = '/glade/p/cgd/tss/people/oleson/modify_param/clm5_params.c200402_kwo.c200422.nc'\n",
    "        self._basepftfile = '/glade/p/cgd/tss/people/oleson/modify_param/clm5_params.c200624_kwo.c200707.nc'\n",
    "        \n",
    "        # create the pftfile as a copy of the basepftfile\n",
    "        # note this will create a file for each ensemble member, regardless of if param mods are needed\n",
    "        cmd = 'cp '+self._basepftfile+' '+self._pftfile\n",
    "        os.system(cmd)\n",
    "        print('working on '+self._pftfile)\n",
    "        \n",
    "        # create the nlfile\n",
    "        # note this will create a file for each ensemble member, regardless of if nl mods are needed\n",
    "        with open(self._nlfile,\"w\") as file:\n",
    "            output = \"! user_nl_clm namelist options written by generate_params:\\n\"\n",
    "            file.write(output)\n",
    "        print('working on '+self._nlfile)\n",
    "            \n",
    "        # read in the pftfile using netCDF4 package\n",
    "        dset = netCDF4.Dataset(self._pftfile,'r+')\n",
    "        \n",
    "        # modify the param/nl files\n",
    "        if sampling_protocol == \"OAAT\":\n",
    "            for paramname in self.get_names():\n",
    "                # for OAAT, only modify if value is not 'None'\n",
    "                if self._paraminfo[paramname].value is not None:\n",
    "                    # params file\n",
    "                    if self._paraminfo[paramname].location == \"P\":\n",
    "                        print(paramname+' modified in pftfile')\n",
    "                        dset[paramname][:] = self._paraminfo[paramname].value\n",
    "                    # namelist\n",
    "                    elif self._paraminfo[paramname].location == \"N\":\n",
    "                        print(paramname+' modified in nlfile')\n",
    "                        with open(self._nlfile,\"a\") as file: # key is using \"a\" for append option\n",
    "                            output = \"%s=%s\\n\" % (paramname, self._paraminfo[paramname].value) #round??\n",
    "                            file.write(output)\n",
    "\n",
    "        # TO DO: LHC code for writing files\n",
    "        elif sampling_protocol == \"LHC\":\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # need to \"close\" netcdf file to write out\n",
    "        dset.close() \n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        i = int(self._name)\n",
    "        return \"Ensemble member %s\" % (str(i+1), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add these or other unit tests to Member class itself\n",
    "# Check every time the code updates, or adding new functionality\n",
    "\n",
    "# testing out the class/dictionary functionality\n",
    "member_test_dict = {\"M1\": Member(\"M1\", paraminfo=test_dict),\n",
    "             \"M2\": Member(\"M2\", paraminfo=test_dict),\n",
    "             \"M3\": Member(\"M3\", paraminfo=None),\n",
    "             \"M4\": Member(\"M4\", paraminfo=None)\n",
    "            }\n",
    "\n",
    "# example of adding a new member\n",
    "member_test_dict[\"new_member\"] = Member(\"new_member\", paraminfo=test_dict)\n",
    "\n",
    "# example of setting the name\n",
    "member_test_dict[\"new_member\"].name = \"M5\"\n",
    "\n",
    "# look at the test dictionary\n",
    "for key in member_test_dict:\n",
    "    print(member_test_dict[key])\n",
    "    \n",
    "# look at a member's paraminfo in the test dictionary\n",
    "member_test_dict['M1'].paraminfo\n",
    "\n",
    "# look at a member's paraminfo for a specific parameter\n",
    "member_test_dict['M1'].paraminfo['P1']\n",
    "\n",
    "# get the list of parameter names\n",
    "member_test_dict['M1'].get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a class for converting numpy arrays to be JSON serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" \n",
    "    Special json encoder for numpy types\n",
    "    \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class for organizing the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    \"\"\"\n",
    "    Stores and works with a bunch of Members.\n",
    "    \"\"\"\n",
    "    \n",
    "    # assign the basepftfile\n",
    "    #_basepftfile = \"../basecase/clm5_params.c200717.nc\"\n",
    "    #_basepftfile = '/glade/p/cgd/tss/people/oleson/modify_param/clm5_params.c200402_kwo.c200422.nc'\n",
    "    _basepftfile = '/glade/p/cgd/tss/people/oleson/modify_param/clm5_params.c200624_kwo.c200707.nc'\n",
    "    \n",
    "    # NOTE: here using an example lnd_in file to pull in default namelist values\n",
    "    # Could also parse the namelist defaults file, see: https://github.com/ESCOMP/CTSM/blob/e2b9745d81ed5cb7cd7f5d6098edf506a4956335/bld/namelist_files/namelist_defaults_ctsm.xml\n",
    "    _thedir = '/glade/work/djk2120/ctsm_hardcode_co/cime/scripts/clm50c6_ctsmhardcodep_2deg_GSWP3V1_Sparse250_2000/CaseDocs/'\n",
    "    _thefil = 'lnd_in'\n",
    "    _lndin = _thedir+_thefil\n",
    "    \n",
    "    def __init__(self, csvfile, sampling_protocol):\n",
    "        self._sampling_protocol = sampling_protocol\n",
    "        \n",
    "        # Read in csv data, filtering by the \"include\" column\n",
    "        data = pd.read_csv(csvfile,header=0,skiprows=[1]) # modify read_csv to account for header spanning 2 rows\n",
    "        included = data['include'] == 1\n",
    "        params_full = data.loc[included,['name','location','min','max','pft_mins','pft_maxs']]\n",
    "\n",
    "        # reset indexing and get rid of excel row number\n",
    "        params = params_full.reset_index(drop=True)\n",
    "        \n",
    "        # get number of parameters\n",
    "        self._nparam = len(params['name'])\n",
    "        \n",
    "        # declare a dictionary to store parameter information\n",
    "        self._params_dict = {}\n",
    "        \n",
    "        # read in default pftfile\n",
    "        def_params = xr.open_dataset(self._basepftfile)\n",
    "        \n",
    "        # reading in the default values\n",
    "        # loop over parameters grabbing name and location\n",
    "        for name,loc in zip(params['name'],params['location']):      \n",
    "            \n",
    "            # select parameters located in the params file\n",
    "            if loc=='P':\n",
    "                # getting parameter dims (i.e., checking for segment variation)\n",
    "                dims = len(def_params[name].values.shape)\n",
    "                if dims<2:\n",
    "                    # no segment variation\n",
    "                    x = def_params[name].values\n",
    "                else:\n",
    "                    # segment variation: ck,kmax,psi50,rootprof_beta\n",
    "                    # assumes the same values are applied across segments\n",
    "                    # TO DO: check this assumption, appears not true for rootprof_beta\n",
    "                    x = def_params[name][0,:].values\n",
    "                self._params_dict[name] = ParamInfo(name, defval=x, loc='P')\n",
    "            \n",
    "            # select namelist parameters\n",
    "            elif loc=='N':\n",
    "                # build a command to search lndin for the parameter by name and put output in a tmp file\n",
    "                cmd = 'grep '+name+' '+self._lndin+' > tmp.txt'\n",
    "                ret = os.system(cmd)\n",
    "                # checking for nonzero return code, meaning parameter is not found\n",
    "                if ret != 0:\n",
    "                    # TO DO: will need to address these special cases somehow...\n",
    "                    print(name+' not found')\n",
    "                else:\n",
    "                    f = open('tmp.txt', 'r')\n",
    "                    # parse the value from the parameter name\n",
    "                    tmp = f.read().split()[2]\n",
    "                    f.close()\n",
    "                    # cases where scientific notation (?) is specified by a \"d\"\n",
    "                    # TO DO: there may be other special cases as well (e.g., scientific notation as an \"e\"?)\n",
    "                    if 'd' in tmp:\n",
    "                        tmp = tmp.split('d')\n",
    "                        x = float(tmp[0])*10**float(tmp[1])\n",
    "                    else:\n",
    "                        x = float(tmp)\n",
    "                    self._params_dict[name] = ParamInfo(name, defval=x, loc='N')\n",
    "        \n",
    "        # assigning min and max values\n",
    "        if sampling_protocol == 'OAAT':\n",
    "            for i in range(self._nparam):\n",
    "                # check for pft variation\n",
    "                if params['min'].values[i]=='pft': # assumes \"pft\" is written in both min and max cells\n",
    "                    self._params_dict[params['name'].values[i]].min = np.fromstring(params['pft_mins'][i],dtype='float',sep=',')\n",
    "                    self._params_dict[params['name'].values[i]].max = np.fromstring(params['pft_maxs'][i],dtype='float',sep=',')\n",
    "                # check for \"XXpercent\" perturb from default\n",
    "                elif \"percent\" in params['min'].values[i]: # assumes \"percent\" is written in both min and max cells\n",
    "                    percent_perturb_min = float(params['min'].values[i].split(\"percent\")[0])\n",
    "                    percent_perturb_max = float(params['max'].values[i].split(\"percent\")[0])\n",
    "                    percent_min_values = self._params_dict[params['name'].values[i]].default*(1 - percent_perturb_min/100)\n",
    "                    percent_max_values = self._params_dict[params['name'].values[i]].default*(1 + percent_perturb_max/100)            \n",
    "                    self._params_dict[params['name'].values[i]].min = percent_min_values\n",
    "                    self._params_dict[params['name'].values[i]].max = percent_max_values        \n",
    "                else:\n",
    "                    # assign min/max values directly\n",
    "                    self._params_dict[params['name'].values[i]].min = params['min'].values[i]\n",
    "                    self._params_dict[params['name'].values[i]].max = params['max'].values[i]\n",
    "        \n",
    "        elif sampling_protocol == 'LHC':\n",
    "            # TO DO: assign LHC min/maxes\n",
    "            pass\n",
    "        \n",
    "        # declare a dictionary to store member information\n",
    "        self._members = {}\n",
    "        \n",
    "        # set the number of ensemble members\n",
    "        if sampling_protocol == 'OAAT':\n",
    "            # number of samples is twice the number of parameters (min and max perturbations)\n",
    "            nsamp = 2*self._nparam\n",
    "        elif sampling_protocol == 'LHC':\n",
    "            # define sample size for LHC (user-specified)\n",
    "            nsamp = 10\n",
    "        \n",
    "        # create the members\n",
    "        # need to \"deepcopy\" the dictionary for each member so they can be modified independently\n",
    "        for i in range(nsamp):\n",
    "            self._members[i] = Member(str(i), copy.deepcopy(self._params_dict))\n",
    "        \n",
    "        # loop over members and calculate parameter values for each member                \n",
    "        # TO DO: OAAT ONLY - NEED TO ADD LHC CODE\n",
    "        doneparams = []\n",
    "        for member in self._members:\n",
    "            for paramname in self._members[member].get_names():\n",
    "                # check if this parameter has already been assigned\n",
    "                if paramname in doneparams:\n",
    "                    continue\n",
    "                # check if this is a min or max perturbation\n",
    "                if int(self._members[member].name)%2 == 0:\n",
    "                    # min values\n",
    "                    self._members[member].paraminfo[paramname].value = self._members[member].paraminfo[paramname].min\n",
    "                    break\n",
    "                else:\n",
    "                    # max values\n",
    "                    self._members[member].paraminfo[paramname].value = self._members[member].paraminfo[paramname].max\n",
    "                    # parameter is \"done\" after creating min/max ensemble members in sequence\n",
    "                    doneparams.append(paramname)\n",
    "                    break\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def params(self):\n",
    "        return self._params_dict\n",
    "    \n",
    "    @property\n",
    "    def members(self):\n",
    "        return self._members\n",
    "    \n",
    "    def output_files(self):\n",
    "        \"\"\"\n",
    "        Loop over members in the ensemble and call the write function.\n",
    "        \"\"\"\n",
    "        \n",
    "        for member in self._members:\n",
    "            self._members[member].write(self._sampling_protocol)\n",
    "    \n",
    "    def save_psets(self, ensemble_name):\n",
    "        \"\"\"\n",
    "        Save the parameter values for the ensemble.\n",
    "        \"\"\"\n",
    "\n",
    "        # build the file name with the prefix (ensemble type)\n",
    "        psetsfile = \"../parameter_sets/\"+self._sampling_protocol+\"_\"+ensemble_name+\".txt\"\n",
    "        #psetsfile = \"../parameter_sets/\"+self._sampling_protocol+\"_\"+ensemble_name+\".json\"\n",
    "        \n",
    "        # TO DO: figure out how to organize pset info\n",
    "\n",
    "        # Currently this writes a very long text file, but all the information is there\n",
    "        # Question is for reading this info back in for analysis, what is the best way to store the pset info\n",
    "        with open(psetsfile, 'w') as fp:\n",
    "            for member in self._members:\n",
    "                fp.write(str(self._members[member]) + '\\n')\n",
    "                for paramname in self._members[member].get_names():\n",
    "                    fp.write(str(self._members[member].paraminfo[paramname]) + '\\n')\n",
    "                    fp.write('\\n')\n",
    "                fp.write('\\n')\n",
    "        \n",
    "        # Another option: Create a new dictionary converting numpy arrays to lists so they are serializable with JSON\n",
    "        # But then they are not readable as numpy arrays after saving out the JSON\n",
    "        \n",
    "        # This JSON hack method doesn't work because self._members is a dictionary of dictionaries\n",
    "        #dumped = json.dumps(self._members, cls=NumpyEncoder)\n",
    "        #with open(psetsfile, 'w') as fp:\n",
    "            #json.dump(dumped, fp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this Ensemble class with the input csv file\n",
    "newEns = Ensemble('params.csv', 'OAAT')\n",
    "\n",
    "# get the params_dict - but which member do the values correspond to? none of the \"value\" entries are set\n",
    "#newEns.params\n",
    "\n",
    "# example of how to print member/param info\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member])\n",
    "#    print(newEns.members[member].paraminfo)\n",
    "    \n",
    "# example of how to print paraminfo for a given member\n",
    "#newEns.members[7].paraminfo\n",
    "\n",
    "# example of how to print paraminfo of a specific parameter for a given member\n",
    "#newEns.members[0].paraminfo['fff']\n",
    "\n",
    "# example of how to print paraminfo of a specific parameter for all members\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member].paraminfo['fff'])\n",
    "\n",
    "# example of how to print the \"value\" info of a specific parameter for all members\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member].paraminfo['fff'].value)\n",
    "\n",
    "# get parameter names for a specific ensemble member\n",
    "#newEns.members[0].get_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseflow_scalar:\n",
       "\tloc = N\n",
       "\tdefault = 0.001\n",
       "\tmin = 0.0005\n",
       "\tmax = 0.1\n",
       "\tvalue = None"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newEns.members[1].paraminfo['baseflow_scalar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing writing out param and nl files\n",
    "newEns.output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing writing out ensemble info, need to provide a name for the Ensemble\n",
    "newEns.save_psets('test0001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notes on parameter testing:\n",
    "* don't currently have checks to see if min or max are equivalent to default value (don't change params files / don't make a namelist mod?) - precision/round-off errors could be important here\n",
    "* `rootprof_beta` has slighty different default values across variants, code currently assumed the same values applied across these secondary dims\n",
    "* spreadsheet values of `rootprof_beta` do not span all pfts, code fails to project these values across the existing param file\n",
    "* haven't yet included parameters with dependencies (e.g., \"these three terms need to add up to 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: integrate this code above for LHC option\n",
    " * careful, each time you run LHC you get a new random draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sampling_protocol == 'LHC':\n",
    "    # define sample size (number of ensemble members)\n",
    "    nsamp = 10\n",
    "\n",
    "    # Generate the latin hypercube sample\n",
    "    lhd = lhs(nparam, samples=int(nsamp))\n",
    "    # lhd is a 2D array indexed by ensemble member x parameter\n",
    "    \n",
    "    # figure out how many pft-dependent params there are in this sample\n",
    "    npftparam = sum(params['min']=='pft')\n",
    "    \n",
    "    if npftparam>0:\n",
    "        # get dataframe index of first pft param\n",
    "        pftfirstind = params.index[params['min']=='pft'][0]\n",
    "        \n",
    "        # get number of pfts\n",
    "        npft = len(np.fromstring(params['pft_mins'][pftfirstind],dtype='float',sep=','))\n",
    "        \n",
    "        # set up numpy array to store pft-specific values\n",
    "        pft_array = np.nan*np.ones([npftparam,npft,nsamp])\n",
    "        \n",
    "        for j in range(npftparam):\n",
    "            # get the index for the current pft param\n",
    "            pftind = params.index[params['min']=='pft'][j]\n",
    "            \n",
    "            # get min values\n",
    "            min_pft_array = np.fromstring(params['pft_mins'][pftind],dtype='float',sep=',')\n",
    "            # max values\n",
    "            max_pft_array = np.fromstring(params['pft_maxs'][pftind],dtype='float',sep=',')\n",
    "            \n",
    "            # loop over samples and calculate parameter values for each pft\n",
    "            for i in range(nsamp):\n",
    "                pft_array[j,:,i] = (max_pft_array - min_pft_array)*lhd[i,pftind] + min_pft_array\n",
    "                # can't store pft_array as a pandas dataframe because it's 3D\n",
    "                # unless there is some alternate way to store this data?\n",
    "    \n",
    "    # initialize min/max arrays - for params without pft-variation\n",
    "    min_array = np.nan*np.ones(nparam)\n",
    "    max_array = np.nan*np.ones(nparam)\n",
    "    \n",
    "    # generate arrays with min and max values\n",
    "    for i in range(nparam):\n",
    "        if params['min'].values[i]=='pft':\n",
    "            # TO DO: what's a good placeholder, to denote need to reference pft_array?\n",
    "            # numpy doesn't like assigning a string to an existing array of floats\n",
    "            # for now, just print a message\n",
    "            print('skipping '+params['name'].values[i]+'...this parameter varies with PFT')\n",
    "            \n",
    "            # Numpy doesn't like assigning an array to a single index in an existing array\n",
    "            # The problem is still that I'm declaring min_array before trying to assign values\n",
    "            # If I could build it all at once, numpy would allow for nested arrays\n",
    "            #min_array[i] = np.fromstring(params['pft_mins'].values[i],dtype='float',sep=',')\n",
    "            #max_array[i] = np.fromstring(params['pft_maxs'].values[i],dtype='float',sep=',')\n",
    "        else:\n",
    "            # assign min/max values\n",
    "            min_array[i] = float(params['min'].values[i])\n",
    "            max_array[i] = float(params['max'].values[i])\n",
    "            \n",
    "    # calculate parameter values; skip pft params (NaNs in min/max arrays)\n",
    "    param_array = (max_array - min_array)*lhd + min_array\n",
    "\n",
    "# store psets in a pandas dataframe\n",
    "#psets = pd.DataFrame(data=param_array, index=None, columns=params['name'])\n",
    "#psets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-analysis)",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
